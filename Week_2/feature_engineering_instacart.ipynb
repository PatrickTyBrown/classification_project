{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Setup & Feature Engineering With Instacart!\n",
    "\n",
    "The first goal of this notebook is to first show how we can take a bunch of raw, relational data and manipulate it into the format of a machine learning problem (binary classification). This is the sort of thing we'll often be given in a business setting - information that's been collected with no clear guidance about how we can frame this information as a predictive task in the $X$ features, $y$ target style.\n",
    "\n",
    "The second goal of this notebook is to expose you to feature engineering ideas and best practices. Knowing how to select models and tune hyperparameters is very important, but models can only be as good as the quality of the features that you provide to them. In practical machine learning, a huge amount of time is spent engineering and selecting features to add signal to the problem, and you can often get a lot more additional value from well-constructed features than from hyperparameter fine tuning. Hence it's very important to be able to apply domain knowledge, think extensively about what features should matter, and derive them to include in your model.    \n",
    "\n",
    "**The data for this notebook is a subset of the [kaggle instacart dataset](https://www.kaggle.com/c/instacart-market-basket-analysis/data)**: the files in the `instacart_data_subset` folder are all the same as the original except that all the order data is drawn from a 5000 user subset for the sake of less memory and more speed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow: \n",
    "\n",
    "1. **Problem setup and baselining**\n",
    "2. **Feature engineering to improve our model**\n",
    "3. **Feature engineering exercises and future ideas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem setup and baselining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's get a quick feel for the data we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip  -o data/instacart_data_subset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = 'instacart_data_subset/'\n",
    "df_orders = pd.read_csv(path + 'orders_subset.csv')\n",
    "df_orders.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_products_prior = pd.read_csv(path + 'order_products__prior_subset.csv')\n",
    "df_order_products_prior.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_products_train = pd.read_csv(path + 'order_products__train_subset.csv')\n",
    "df_order_products_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to combine the order/product information with user information, so we'll go ahead and merge the `order_products` tables with the `orders` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_products_train = df_order_products_train.merge(df_orders.drop('eval_set', axis=1), on='order_id')\n",
    "df_order_products_prior = df_order_products_prior.merge(df_orders.drop('eval_set', axis=1), on='order_id')\n",
    "\n",
    "df_order_products_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll set up the classification problem. For the instacart challenge, the given task is to predict which products will show up again in a user's next order based on their entire product order history. We can worry about aggregating to the cart level later, but understand for now that this problem will require us to make **individual binary predictions for every unique user-product combination** in the order history, where the target is 1 or 0 for if that product shows up in the user's next/most current order.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that in mind, we'll create a **`df_X` as our ML-formatted dataframe**, with a user-product aggregated version of the `order_products_prior` data. We'll go ahead and count the total # of times the user has ordered each product as our first feature since we're already doing a user-product aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_product = (df_order_products_prior.groupby(['product_id','user_id'],as_index=False) \n",
    "                                          .agg({'order_id':'count'}) \n",
    "                                          .rename(columns={'order_id':'user_product_total_orders'}))\n",
    "\n",
    "train_ids = df_order_products_train['user_id'].unique() \n",
    "df_X = df_user_product[df_user_product['user_id'].isin(train_ids)]\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to get our labels. To do this, we'll group our current cart data (`order_products_train`) by user and collect a set of the items in that cart. Then we can merge with `df_X` and iterate through the rows to get labels for whether each product occurs in the latest cart.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_carts = (df_order_products_train.groupby('user_id',as_index=False)\n",
    "                                      .agg({'product_id':(lambda x: set(x))})\n",
    "                                      .rename(columns={'product_id':'latest_cart'}))\n",
    "\n",
    "df_X = df_X.merge(train_carts, on='user_id')\n",
    "df_X['in_cart'] = (df_X.apply(lambda row: row['product_id'] in row['latest_cart'], axis=1).astype(int))\n",
    "\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now we actually have a dataset that's shaped as a binary classification problem: **`in_cart` is our target**, and **each observation is a unique user-product combination** based on the entire order history for users in our current cart data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning to EDA and Baselining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data formatted into a ML problem, we should start getting a feel for the problem and create some simple visuals. In particular, as we build features we'll want to **look for visual evidence that the data is separable using these features**. Since we'll be using logistic regression for baselining, we ideally want to find indications of linear separability.  \n",
    "\n",
    "We should immediately check out the distribution of our labels and know that we're working with an **imbalanced classification task** (always check this first!). This is analagous to the first step of checking the continuous target distribution in a regression problem. We'll definitely want to account for the imbalance later (though not in this notebook) when we try to optimize our F1 score, the chosen metric for scoring our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pcts = df_X.in_cart.value_counts(normalize=True) \n",
    "print(target_pcts)\n",
    "\n",
    "target_pcts.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a feel for our target, we'll start looking for feature-target relationships. Since we'll do this repeatedly on a sample of the data as we build out features, let's write another utility function that generates a seaborn pairplot matrix colored by the target value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(df, sample_size=500):\n",
    "    \n",
    "    sample = (df.drop(['product_id','user_id','latest_cart'],axis=1)\n",
    "                .sample(1000, random_state=44)) \n",
    "    sns.pairplot(sample,hue='in_cart', plot_kws=dict(alpha=.3, edgecolor='none'))\n",
    "\n",
    "plot_features(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit hard to see, but in `the user_product_total_orders` plot there's evidence that higher values are associated with higher likelihood of a positive target (this is intuitive). Don't be deceived by the longer right tail for the negative target samples, this is likely an artifact of the class imbalance.\n",
    "\n",
    "Right now this looks like a very meagre machine learning problem! We only have 1 usable feature and it doesn't look like a strong one - the total orders placed for each user-product combination. Let's use a simple logistic model with this feature as a baseline, and see how much predictive power we can add to this baseline by **building out our feature set with feature engineering**.\n",
    "\n",
    "For this problem, we want to be **extra careful about validation/testing**. If we do a simple train/test split, we'll end up with users that occur in both the training and test data and run the risk of overfitting to the tendencies of specific users. Instead, we'll manually sample 20% of the users to put into our test set, and use the remaining 80% of users for the training data. Since we'll be doing this several times as we build out feature sets, we'll encapsulate the sampling process in a `get_user_split_data` function that mimics the behavior of sklearn's `train_test_split`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_split_data(df, test_size=.2, seed=42):\n",
    "\n",
    "    rs = np.random.RandomState(seed)\n",
    "    \n",
    "    total_users = df['user_id'].unique() \n",
    "    test_users = rs.choice(total_users, \n",
    "                           size=int(total_users.shape[0] * test_size), \n",
    "                           replace=False)\n",
    "\n",
    "    df_tr = df[~df['user_id'].isin(test_users)]\n",
    "    df_te = df[df['user_id'].isin(test_users)] \n",
    "\n",
    "    y_tr, y_te = df_tr['in_cart'], df_te['in_cart']\n",
    "    X_tr = df_tr.drop(['product_id','user_id','latest_cart','in_cart'],axis=1) \n",
    "    X_te = df_te.drop(['product_id','user_id','latest_cart','in_cart'],axis=1)\n",
    "\n",
    "    return X_tr, X_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this splitting function in hand, we're ready to train and evaluate our simple baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = get_user_split_data(df_X)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr, y_tr)\n",
    "f1_score(lr.predict(X_te), y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar is set low!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm our visual-driven assumption that a higher number of past product orders is associated with higher likelihood of being in the next cart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering to improve our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is think critically about the predictive task and the types of features that we need to use. We should draw heavily on domain knowledge and be open to trial and error. \n",
    "\n",
    "Since our observations are unique combinations of user-product, we'll have multiple sources of features that are highly relevant to making a prediction about the purchasing behavior for the upcoming/most current order. We can break this problem down in terms of **qualities of human behavior** and figure out how to capture them numerically.\n",
    "\n",
    "### Feature Types:\n",
    "\n",
    "* **Product** features: general information about product purchase patterns across ALL users. The category of the product, its general popularity, how high priority the item tends to be, etc.\n",
    "* **User** features: information about specific user behavior. How many items do they tend to order, how long has it been since they've last ordered, what time of day do they usually order, etc. \n",
    "* **User-Product** features: information about product-specific user behavior. How often have they ordered this product, how high-priority does it tend to be for them, how long has it been since they've ordered this product, etc.\n",
    "\n",
    "When engineering 10s or hundreds of features, it can quickly become tricky to keep track of all our code and feature outputs. Here are a couple of best practices:\n",
    "\n",
    "  1. Use consistent naming conventions for features of the same type \n",
    "  2. Build features at the same level of aggregation at the same time, and track them in a dedicated dataframe. Merge back into the ML-formatted dataframe at the end of the process.\n",
    "  \n",
    "With this in mind, we'll start with product level features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product features\n",
    "\n",
    "Here we'll create 2 simple product-level features, merge them into the ML dataframe, and run a new model as a 2nd baselining step. By **iteratively baselining** like this, we can make sure that each set of features we're adding to the mix is adding real predictive value.\n",
    "\n",
    "We'll gauge each product's overall popularity by counting its total orders across all users, and also gauge its typical priority level in an order by averaging its `add_to_cart_order`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_features = ['product_total_orders','product_avg_add_to_cart_order']\n",
    "\n",
    "df_prod_features = (df_order_products_prior.groupby(['product_id'],as_index=False)\n",
    "                                           .agg(OrderedDict(\n",
    "                                                   [('order_id','nunique'),\n",
    "                                                    ('add_to_cart_order','mean')])))\n",
    "df_prod_features.columns = ['product_id'] + prod_features\n",
    "df_prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_X.merge(df_prod_features, on='product_id')\n",
    "\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we expand our feature set, lets generate a new set of visuals to study the feature-target relationships and look for separability.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, **this problem still looks hard**. We don't see any strong linear signals or particularly compelling evidence of nonlinear separability in these charts. But we probably do have better signals than before in our 1-feature baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = get_user_split_data(df_X)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_tr, y_tr)\n",
    "f1_score(lr.predict(X_te), y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're able to do slightly better with the addition of just a few product specific features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User features\n",
    "\n",
    "Here we'll create 4 user-level features, then merge into `df_X` and benchmarka model as before.\n",
    "\n",
    "There are a number of components of user behavior that should be critical to measure. We'd like to know if our users have made many or few orders, the average number of products they buy in an order, how many different products they've bought over time, and how long they typically wait between orders. Thinking about purchasing tendencies, all of these factors could play a role in determining what to expect from the next cart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = ['user_total_orders','user_avg_cartsize','user_total_products','user_avg_days_since_prior_order']\n",
    "\n",
    "df_user_features = (df_order_products_prior.groupby(['user_id'],as_index=False)\n",
    "                                           .agg(OrderedDict(\n",
    "                                                   [('order_id',['nunique', (lambda x: x.shape[0] / x.nunique())]),\n",
    "                                                    ('product_id','nunique'),\n",
    "                                                    ('days_since_prior_order','mean')])))\n",
    "\n",
    "df_user_features.columns = ['user_id'] + user_features\n",
    "df_user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_X.merge(df_user_features, on='user_id')\n",
    "df_X = df_X.dropna() # note that this is naive NaN handling for simplicity\n",
    "df_X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot more features to spend some time looking at now. Do you see any clear separator features or two-way interactions that might be good separators? The problem is still hard, nothing jumps out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = get_user_split_data(df_X)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_tr, y_tr)\n",
    "f1_score(lr.predict(X_te), y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, our model improvement confirms that these features were a worthwhile addition of predictive value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Product features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our 3rd feature engineering step, we'll create 2 more user-product features to add to our benchmark.\n",
    "\n",
    "Here we want to get a sense of how much priority each user places on each product by looking at the typical `add_to_cart_order` for that user-product combination. We also want to get a feature for % of times a product occurs across all of a user's orders -- we'll do that at the end by taking the original `user_product_total_orders` feature we grabbed and dividing it by the `user_total_orders` feature we derived in the user features section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prod_features = ['user_product_avg_add_to_cart_order']\n",
    "\n",
    "df_user_prod_features = (df_order_products_prior.groupby(['product_id','user_id'],as_index=False) \\\n",
    "                                                .agg(OrderedDict(\n",
    "                                                     [('add_to_cart_order','mean')])))\n",
    "\n",
    "df_user_prod_features.columns = ['product_id','user_id'] + user_prod_features \n",
    "df_user_prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_X.merge(df_user_prod_features,on=['user_id','product_id'])\n",
    "df_X['user_product_order_freq'] = df_X['user_product_total_orders'] / df_X['user_total_orders'] \n",
    "df_X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we work towards an increasingly complex model (more and more features), it's getting harder to study all the visuals! But look at the bottom row, corresponding to the \"user_product_order_freq\" feature. There seems to be some separation to be had here, which makes sense - how often a user has ordered a product in the past should matter a lot for predicting the future. So perhaps we've made a bit of a breakthrough, will it reflect in the model score? \n",
    "\n",
    "As a hint about model selection for this problem, think about the geometric structure of the relationships above. Do they really look very linear? Our EDA already suggests that nonlinear models may do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = get_user_split_data(df_X)\n",
    "\n",
    "lr = LogisticRegression(C=1, max_iter=1000)\n",
    "lr.fit(X_tr, y_tr)\n",
    "f1_score(lr.predict(X_te), y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've come a long way, but have a ways yet to go. We should be able to improve our F1 with a combination of:\n",
    "\n",
    "    1. More/better features\n",
    "    2. More training data (we have lots more available)\n",
    "    3. Better handling of the class imbalance issue / decision threshold (topic for future lecture)\n",
    "    4. More sophisticated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving our ML dataframe with features for future use:\n",
    "df_X.to_csv('instacart_data_subset/instacart_df_X_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature engineering exercises and future ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add product category / aisle information as categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another user-product feature that computes how many orders it's been since the user ordered that product \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another user-product feature that computes the % of times a product shows up consecutively in the user's orders\n",
    "# (i.e. they reordered it immediately in the next order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We haven't used the data on order time / day of week at all yet. We could use this to measure the typical times \n",
    "# products tend to be ordered (both generically and at the user-product level), and quantify the difference\n",
    "# between the time of the latest order and these typical times to pick up new signal around ordering patterns.\n",
    "\n",
    "# Modify the product and user-product features to compute average hour of day and day of week. Add these to df_X,\n",
    "# Then add features of the form user_product_avg_hod_delta that take the dif of the current order time and the avg. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far the way we've used the order history treats the entire history on equal terms - for example, user-product \n",
    "# order frequency treats orders from months ago the same as recent ones. Come up with features that focus more\n",
    "# on the most recent orders or give them more weight than older ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
