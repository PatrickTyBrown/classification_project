{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some fake data for linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1fd98a90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-20,20)\n",
    "y = 0.3 * x + np.random.randn(40)\n",
    "plt.scatter(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's assume we know the intercept (zero) and noise distribution (standard normal). Our goal is just to find the slope. So for the $n$th point, we have\n",
    "\n",
    "$$\n",
    "y_n \\sim \\mathcal{N}(\\beta x_n, 1)\n",
    "$$,\n",
    "\n",
    "which visually looks like the below (with 3 points / conditional distributions highlighted):\n",
    "\n",
    "![linear_conditionals](linear_conditionals.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume the $y$ values are independent. By the MLE framework's approach, the parameter $\\beta$ is assumed to be unknown, but fixed. So the probability of the observation is just"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P\\left(y\\ |\\ \\beta\\right)\t\n",
    "= \\prod_{N\\text{ points}} P(y_n\\ |\\ \\beta)\n",
    "=\\prod_{N\\text{ points}}\\mathcal{N}\\left(y_{n}\\ |\\ \\beta x_{n},1\\right)\n",
    "\t=\\prod_{N\\text{ points}}\\left(\\frac{1}{\\sqrt{2\\pi}}\\exp\\left\\{ \\frac{-\\left(y_{n}-\\beta x_{n}\\right)^2}{2}\\right\\} \\right)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been considering this as a function of $y$, but since we've observed data, we're really more interested in it as a function of $\\beta$. This is the *likelihood*, \n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\beta|y) = P(y|\\beta)\n",
    "$$\n",
    "\n",
    "We're interesting in the *maximum likelihood estimate*, which estimates the parameter by maximizing the likelihood function. In other words, **finding the value of the parameter with the highest probability of generating the data we did, in fact, observe**.\n",
    "\n",
    "So combining what we have to this point, we'd like to estimate $\\beta$ by finding the value that maximizes the likelihood,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\beta|y) = \\prod_{N\\text{ points}}\\left(\\frac{1}{\\sqrt{2\\pi}}\\exp\\left\\{ \\frac{-\\left(y_{n}-\\beta x_{n}\\right)^2}{2}\\right\\} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good. What's a good way to maximize things? There are lots, but here it will probably be quickest to work in terms of derivatives. But differentiating a product is a mess. Do we really have to do it this way? Spoiler: no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be so much easier to work in terms of a sum, instead of a product. Then the derivative would be easy - we could just calculate term by term.\n",
    "\n",
    "But we *can* work in terms of a sum! We can simply exploit the fact that **maximizing a value is equivalent to maximizing the log of that value**. Let's just take the log of both sides:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\log \\mathcal{L}(\\beta|y) \n",
    "&= \\log \\prod_{N\\text{ points}}\\left(\\frac{1}{\\sqrt{2\\pi}}\\exp\\left\\{ \\frac{-\\left(y_{n}-\\beta x_{n}\\right)^2}{2}\\right\\} \\right) \n",
    "\\\\ &= \\sum_{N\\text{ points}} \\log \\left(\\frac{1}{\\sqrt{2\\pi}}\\exp\\left\\{ \\frac{-\\left(y_{n}-\\beta x_{n}\\right)^2}{2}\\right\\} \\right) \n",
    "\\\\ &= \\sum_{N\\text{ points}} \\left[ \\log \\frac{1}{\\sqrt{2\\pi}} - \\frac{\\left(y_{n}-\\beta x_{n}\\right)^2}{2} \\right]\n",
    "\\\\ &= C - \\frac{1}{2}\\sum_{N\\text{ points}} \\left(y_{n}-\\beta x_{n}\\right)^2\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, time for the big reveal. Look at that line. To maximize that, we want to **minimize the negative quantity**. \n",
    "\n",
    "**I.e. for a normal linear regression model, maximizing likelihood is the same as minimizing $\\sum_{N\\text{ points}} \\left(y_{n}-\\beta x_{n}\\right)^2$**, the SSE loss that we know and love."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
